{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-YhhpMmRV1W"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install openai\n",
        "!pip install pinecone-client\n",
        "!pip install google-cloud-storage\n",
        "!pip install Python-dotenv\n",
        "!pip install Firebase-admin\n",
        "!pip install spacy\n",
        "!pip install langchain_openai\n",
        "!pip install pypdf\n",
        "!pip install pdfminer\n",
        "!pip install unstructured\n",
        "!pip install unstructured[pdf]\n",
        "!pip install docx2txt\n",
        "!pip install langchainhub\n",
        "!sudo apt-get install libgl1-mesa-glx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT7vwaqwbuE7"
      },
      "outputs": [],
      "source": [
        "!pip install Pinecone\n",
        "!pip install --quiet langchain_experimental langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTA_FbxncJDB"
      },
      "outputs": [],
      "source": [
        "from operator import le\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_loaders import OnlinePDFLoader\n",
        "import os\n",
        "import spacy\n",
        "import uuid\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.document_loaders import OnlinePDFLoader\n",
        "from langchain_community.vectorstores.pinecone import Pinecone\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.retrieval import create_retrieval_chain\n",
        "\n",
        "# Conversation imports\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
        "from langchain_community.document_loaders import OnlinePDFLoader, TextLoader\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "import shutil\n",
        "import uuid\n",
        "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain.chains import create_extraction_chain\n",
        "from typing import Optional, List\n",
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "from langchain_core.pydantic_v1 import BaseModel\n",
        "from langchain import hub\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGMFlu2xcblg"
      },
      "outputs": [],
      "source": [
        "def load_document():\n",
        "    # use the uploads_dir in your DirectoryLoader\n",
        "    loader = DirectoryLoader(\"./Documents\", glob=\"*.pdf\")\n",
        "    docs = loader.load()\n",
        "    print(\"docs:\", docs)\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1jmpsYKdGdV"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h59iNHezlOE"
      },
      "outputs": [],
      "source": [
        "def upload_documents_service():\n",
        "    pinecone = Pinecone(api_key = \"<YOUR API KEY>\")\n",
        "    index = pinecone.Index(\"<YOUR INDEX NAME>\")\n",
        "    docs = load_document()\n",
        "    for doc in docs:\n",
        "      print(\"current document \",doc)\n",
        "      text = doc.page_content\n",
        "      embeddings_model = OpenAIEmbeddings(openai_api_key=\"<YOUR API KEY>\")\n",
        "      text_splitter = RecursiveCharacterTextSplitter()\n",
        "\n",
        "      #chunks = text_splitter.split_text(text)\n",
        "\n",
        "      # chunks = text_splitter.create_documents([text])\n",
        "      chunks =  text_splitter.create_documents([text])\n",
        "\n",
        "      # embeddings_arrays = embeddings_model.embed_documents(\n",
        "      #     [chunk.page_content.replace(\"\\n\", \" \") for chunk in chunks]\n",
        "      # )\n",
        "\n",
        "      batch_size = 100\n",
        "      batch = []\n",
        "\n",
        "      for idx in range(len(chunks)):\n",
        "          chunk = chunks[idx]\n",
        "          vector = {\n",
        "              \"id\": str(uuid.uuid4()),\n",
        "              \"values\": embeddings_model.embed_query(\n",
        "                  chunk.page_content.replace(\"\\n\", \" \")\n",
        "              ),\n",
        "              \"metadata\": {\n",
        "                  **chunk.metadata,\n",
        "                  \"text\": chunk.page_content,\n",
        "                  \"id\": \"<YOUR HARDCODED ID>\",\n",
        "              },\n",
        "          }\n",
        "          batch.append(vector)\n",
        "\n",
        "          # When batch is full, or it's the last item, upsert the vectors\n",
        "          if len(batch) == batch_size or idx == len(chunks) - 1:\n",
        "              index.upsert(vectors=batch)\n",
        "\n",
        "              # Empty the batch\n",
        "              batch = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cnfWmaRu0ZA_"
      },
      "outputs": [],
      "source": [
        "upload_documents_service()\n",
        "print(\"document uploaded\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
